{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "import time\n", "from collections import Counter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import faiss\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torchvision\n", "from faiss import Kmeans as faiss_Kmeans\n", "from tqdm import tqdm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DEFAULT_KMEANS_SEED = 1234"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Kmeans(object):\n", "    def __init__(\n", "        self, k_list, data, epoch=0, init_centroids=None, frozen_centroids=False\n", "    ):\n", "        \"\"\"\n", "        Performs many k-means clustering.\n", "        Args:\n", "            data (np.array N * dim): data to cluster\n", "        \"\"\"\n", "        super().__init__()\n", "        self.k_list = k_list\n", "        self.data = data\n", "        self.d = data.shape[-1]\n", "        self.init_centroids = init_centroids\n", "        self.frozen_centroids = frozen_centroids\n", "        self.logger = logging.getLogger(\"Kmeans\")\n", "        self.debug = False\n", "        self.epoch = epoch + 1\n", "    def compute_clusters(self):\n", "        \"\"\"compute cluster\n", "        Returns:\n", "            torch.tensor, list: clus_labels, centroids\n", "        \"\"\"\n", "        data = self.data\n", "        labels = []\n", "        centroids = []\n", "        tqdm_batch = tqdm(total=len(self.k_list), desc=\"[K-means]\")\n", "        for k_idx, each_k in enumerate(self.k_list):\n", "            seed = k_idx * self.epoch + DEFAULT_KMEANS_SEED\n", "            kmeans = faiss_Kmeans(\n", "                self.d,\n", "                each_k,\n", "                niter=40,\n", "                verbose=False,\n", "                spherical=True,\n", "                min_points_per_centroid=1,\n", "                max_points_per_centroid=10000,\n", "                gpu=True,\n", "                seed=seed,\n", "                frozen_centroids=self.frozen_centroids,\n", "            )\n", "            kmeans.train(data, init_centroids=self.init_centroids)\n", "            _, I = kmeans.index.search(data, 1)\n", "            labels.append(I.squeeze(1))\n", "            C = kmeans.centroids\n", "            centroids.append(C)\n", "            tqdm_batch.update()\n", "        tqdm_batch.close()\n", "        labels = np.stack(labels, axis=0)\n", "        return labels, centroids"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def torch_kmeans(k_list, data, init_centroids=None, seed=0, frozen=False):\n", "    if init_centroids is not None:\n", "        init_centroids = init_centroids.cpu().numpy()\n", "    km = Kmeans(\n", "        k_list,\n", "        data.cpu().detach().numpy(),\n", "        epoch=seed,\n", "        frozen_centroids=frozen,\n", "        init_centroids=init_centroids,\n", "    )\n", "    clus_labels, centroids_npy = km.compute_clusters()\n", "    clus_labels = torch.from_numpy(clus_labels).long().cuda()\n", "    centroids = []\n", "    for c in centroids_npy:\n", "        centroids.append(torch.from_numpy(c).cuda())\n", "    # compute phi\n", "    clus_phi = []\n", "    for i in range(len(k_list)):\n", "        clus_phi.append(compute_variance(data, clus_labels[i], centroids[i]))\n", "    return clus_labels, centroids, clus_phi"]}, {"cell_type": "markdown", "metadata": {}, "source": ["variance"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}