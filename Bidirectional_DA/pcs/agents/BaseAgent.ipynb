{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import datetime\n", "import logging\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import torch\n", "import torch.backends.cudnn as cudnn\n", "import torch.nn as nn\n", "from pcs.utils import print_info, torchutils\n", "from torch.utils.tensorboard import SummaryWriter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class BaseAgent(object):\n", "    \"\"\"\n", "    General agent class\n", "    Abstract Methods to be implemented:\n", "        _load_datasets\n", "        _create_model\n", "        _create_optimizer\n", "        train_one_epoch\n", "        validate\n", "        load_checkpoint\n", "        save_checkpoint\n", "    \"\"\"\n", "    def __init__(self, config):\n", "        self.config = config\n", "        # set seed as early as possible\n", "        torchutils.set_seed(self.config.seed)\n", "        self.model = None\n", "        self.optim = None\n", "        self.logger = logging.getLogger(\"Agent\")\n", "        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir)\n", "        self.current_epoch = 0\n", "        self.current_iteration = 0\n", "        self.current_val_iteration = 0\n", "        self.val_acc = []\n", "        self.train_loss = []\n", "        self.lr_scheduler_list = []\n", "        print_info(self.logger.info)\n", "        self.starttime = datetime.datetime.now()\n", "        self._choose_device()\n\n", "        # Load Dataset\n", "        self._load_datasets()\n", "        self._create_model()\n", "        self._create_optimizer()\n\n", "        # we need these to decide best loss\n", "        self.current_loss = 0.0\n", "        self.current_val_metric = 0.0\n", "        self.best_val_metric = 0.0\n", "        self.best_val_epoch = 0\n", "        self.iter_with_no_improv = 0\n", "    def get_attr(self, domain, name):\n", "        return getattr(self, f\"{name}_{domain}\")\n", "    def set_attr(self, domain, name, value):\n", "        setattr(self, f\"{name}_{domain}\", value)\n", "        return self.get_attr(domain, name)\n", "    def _choose_device(self):\n", "        # check if use gpu\n", "        self.is_cuda = torch.cuda.is_available()\n", "        if self.is_cuda and not self.config.cuda:\n", "            self.logger.info(\n", "                \"WARNING: You have a CUDA device, so you should probably enable CUDA\"\n", "            )\n", "        self.cuda = self.is_cuda & self.config.cuda\n", "        if self.cuda:\n", "            self.device = torch.device(\"cuda\")\n", "            cudnn.benchmark = True\n", "            if self.config.gpu_device is None:\n", "                self.config.gpu_device = list(range(torch.cuda.device_count()))\n", "            elif not isinstance(self.config.gpu_device, list):\n", "                self.config.gpu_device = [self.config.gpu_device]\n", "            self.gpu_devices = self.config.gpu_device\n\n", "            # set device when only one gpu\n", "            num_gpus = len(self.gpu_devices)\n", "            self.multigpu = num_gpus > 1 and torch.cuda.device_count() > 1\n", "            if not self.multigpu:\n", "                torch.cuda.set_device(self.gpu_devices[0])\n", "            gpu_devices = \",\".join([str(_gpu_id) for _gpu_id in self.gpu_devices])\n", "            self.logger.info(f\"User specified {num_gpus} GPUs: {gpu_devices}\")\n", "            self.parallel_helper_idxs = torch.arange(len(self.gpu_devices)).to(\n", "                self.device\n", "            )\n", "            self.logger.info(\"Program will run on *****GPU-CUDA***** \")\n", "            torchutils.print_cuda_statistics(output=self.logger.info, nvidia_smi=False)\n", "        else:\n", "            self.device = torch.device(\"cpu\")\n", "            self.logger.info(\"Program will run on *****CPU*****\\n\")\n", "    def _load_datasets(self):\n", "        raise NotImplementedError\n", "    def _create_model(self):\n", "        raise NotImplementedError\n", "    def _create_optimizer(self):\n", "        raise NotImplementedError\n", "    def run(self):\n", "        \"\"\"\n", "        The main operator\n", "        :return:\n", "        \"\"\"\n", "        try:\n", "            self.train()\n", "            self.cleanup()\n", "        except KeyboardInterrupt as e:\n", "            self.logger.info(\"Interrupt detected. Saving data...\")\n", "            self.backup()\n", "            self.cleanup()\n", "            raise e\n", "        except Exception as e:\n", "            self.logger.error(e, exc_info=True)\n", "    def train(self):\n", "        \"\"\"\n", "        Main training loop\n", "        :return:\n", "        \"\"\"\n", "        if self.config.validate_freq:\n", "            self.validate()\n", "        for epoch in range(self.current_epoch + 1, self.config.num_epochs + 1):\n", "            # early stop\n", "            patience = self.config.optim_params.patience\n", "            if patience and self.iter_with_no_improv > patience:\n", "                self.logger.info(\n", "                    f\"accuracy not improved in {patience} epoches, stopped\"\n", "                )\n", "                break\n", "            # train\n", "            self.current_epoch = epoch\n", "            self.train_one_epoch()\n", "            # validate\n", "            if self.config.validate_freq and epoch % self.config.validate_freq == 0:\n", "                self.validate()\n", "            # adjust\n", "            for sch in self.lr_scheduler_list:\n", "                sch.step()\n", "            # save\n", "            self.save_checkpoint()\n", "    def train_one_epoch(self):\n", "        \"\"\"\n", "        One epoch of training\n", "        :return:\n", "        \"\"\"\n", "        raise NotImplementedError\n", "    def validate(self):\n", "        \"\"\"\n", "        One cycle of model validation\n", "        :return:\n", "        \"\"\"\n", "        raise NotImplementedError\n", "    def backup(self):\n", "        \"\"\"\n", "        Backs up the model upon interrupt\n", "        \"\"\"\n", "        self.summary_writer.close()\n", "        self.save_checkpoint(filename=\"backup.pth.tar\")\n", "    def finalise(self):\n", "        \"\"\"\n", "        Do appropriate saving after model is :finished training\n", "        \"\"\"\n", "        self.backup()\n", "    def cleanup(self):\n", "        \"\"\"\n", "        Undo any global changes that the Agent may have made\n", "        \"\"\"\n", "        if hasattr(self, \"best_val_epoch\"):\n", "            self.logger.info(\n", "                f\"Best Val acc at {self.best_val_epoch}: {self.best_val_metric:.3}\"\n", "            )\n", "        endtime = datetime.datetime.now()\n", "        exe_time = endtime - self.starttime\n", "        self.logger.info(\n", "            f\"End at time: {endtime.strftime('%Y.%m.%d-%H:%M:%S')}, total time: {exe_time.seconds}s\"\n", "        )\n", "    def copy_checkpoint(self, filename=\"checkpoint.pth.tar\"):\n", "        if (\n", "            self.config.copy_checkpoint_freq\n", "            and self.current_epoch % self.config.copy_checkpoint_freq == 0\n", "        ):\n", "            self.logger.info(f\"Backup checkpoint_epoch_{self.current_epoch}.pth.tar\")\n", "            torchutils.copy_checkpoint(\n", "                filename=filename,\n", "                folder=self.config.checkpoint_dir,\n", "                copyname=f\"checkpoint_epoch_{self.current_epoch}.pth.tar\",\n", "            )\n", "    def load_checkpoint(self, filename):\n", "        \"\"\"\n", "        Latest checkpoint loader\n", "        :param file_name: name of the checkpoint file\n", "        :return:\n", "        \"\"\"\n", "        raise NotImplementedError\n", "    def save_checkpoint(self, filename=\"checkpoint.pth.tar\"):\n", "        \"\"\"\n", "        Checkpoint saver\n", "        :param file_name: name of the checkpoint file\n", "        :param is_best: boolean flag to indicate whether current checkpoint's metric is the best so far\n", "        :return:\n", "        \"\"\"\n", "        raise NotImplementedError"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}