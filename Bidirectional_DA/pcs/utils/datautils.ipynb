{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import collections\n", "import os\n", "import random\n", "import shutil\n", "import socket"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import torch\n", "import torchvision\n", "from PIL import Image\n", "from scipy import stats\n", "from sklearn.model_selection import train_test_split\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms"]}, {"cell_type": "markdown", "metadata": {}, "source": ["image_list"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_image_label(image_list):\n", "    image_index = [x.split(\" \")[0] for x in open(image_list)]\n", "    label_list = np.array([int(x.split(\" \")[1].strip()) for x in open(image_list)])\n", "    return image_index, label_list"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_class_map(image_list):\n", "    class_map = {}\n", "    for x in open(image_list):\n", "        key = int(x.split(\" \")[1].strip())\n", "        if key not in class_map:\n", "            class_map[key] = x.split(\" \")[0].split(\"/\")[-2]\n", "    class_map = collections.OrderedDict(sorted(class_map.items()))\n", "    return class_map"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_class_num(image_list):\n", "    # return len(get_class_map(image_list))\n", "    return max(list(get_class_map(image_list).keys())) + 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def describe_image_list(image_list, save_graph=False, label_name=True, is_sort=False):\n", "    _, label_list = create_image_label(image_list)\n", "    label_cnt = np.bincount(label_list)\n", "    print(\n", "        f\"\"\"Image list \\\"{image_list}\\\":\n", "    \\tTotal instances: {len(label_list)}\n", "    \\tTotal class: {len(label_cnt)}\n", "    \\tmax # of class: {np.max(label_cnt)}\n", "    \\tmin # of class: {np.min(label_cnt)}\n", "    \\tmean # of class: {np.mean(label_cnt)}\n", "    \\tmedian # of class: {np.median(label_cnt)}\n", "    \\tvar: {np.var(label_cnt)}\"\"\"\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_fewshot_index(lbd_dataset, whl_dataset):\n", "    lbd_imgs = lbd_dataset.imgs\n", "    whl_imgs = whl_dataset.imgs\n", "    fewshot_indices = [whl_imgs.index(path) for path in lbd_imgs]\n", "    fewshot_labels = lbd_dataset.labels\n", "    return fewshot_indices, fewshot_labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Imagelists(torch.utils.data.Dataset):\n", "    def __init__(\n", "        self,\n", "        image_list,\n", "        root,\n", "        transform=None,\n", "        target_transform=None,\n", "        keep_in_mem=False,\n", "        ret_index=False,\n", "    ):\n", "        # print(image_list)\n", "        imgs, labels = create_image_label(image_list)\n", "        self.imgs = imgs\n", "        self.labels = labels\n", "        self.transform = transform\n", "        self.target_transform = target_transform\n", "        self.root = root\n", "        self.ret_index = ret_index\n", "        self.keep_in_mem = keep_in_mem\n", "        self.loader = pil_loader\n\n", "        # keep in mem\n", "        if self.keep_in_mem:\n", "            images = []\n", "            for index in range(len(self.imgs)):\n", "                path = os.path.join(self.root, self.imgs[index])\n", "                img = self.loader(path)\n", "                if self.transform is not None:\n", "                    img = self.transform(img)\n", "                images.append(img)\n", "            self.images = images\n", "    def __getitem__(self, index):\n", "        \"\"\"\n", "        Args:\n", "            index (int): Index\n", "        Returns:\n", "            tuple: (image, target) where target is\n", "            class_index of the target class.\n", "        \"\"\"\n", "        if self.keep_in_mem:\n", "            img = self.images[index]\n", "        else:\n", "            path = os.path.join(self.root, self.imgs[index])\n", "            img = self.loader(path)\n", "            if self.transform is not None:\n", "                img = self.transform(img)\n", "        target = self.labels[index]\n", "        if self.target_transform is not None:\n", "            target = self.target_transform(target)\n", "        if not self.ret_index:\n", "            return img, target\n", "        else:\n", "            return index, img, target\n", "    def __len__(self):\n", "        return len(self.imgs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["preprocess"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["means = {\"imagenet\": [0.485, 0.456, 0.406]}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stds = {\"imagenet\": [0.229, 0.224, 0.225]}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_augmentation(trans_type=\"aug_0\", image_size=224, stat=\"imagenet\"):\n", "    stat = \"imagenet\"\n", "    mean, std = means[stat], stds[stat]\n", "    image_s = image_size + 32\n", "    data_transforms = {\n", "        \"raw\": transforms.Compose(\n", "            [\n", "                transforms.Resize((image_s, image_s)),\n", "                transforms.CenterCrop(image_size),\n", "                transforms.ToTensor(),\n", "                transforms.Normalize(mean=mean, std=std),\n", "            ]\n", "        ),\n", "        \"aug_0\": transforms.Compose(\n", "            [\n", "                transforms.Resize((image_s, image_s)),\n", "                transforms.RandomHorizontalFlip(),\n", "                transforms.RandomCrop(image_size),\n", "                transforms.ToTensor(),\n", "                transforms.Normalize(mean=mean, std=std),\n", "            ]\n", "        ),\n", "        \"aug_1\": transforms.Compose(\n", "            [\n", "                transforms.RandomResizedCrop(image_size, scale=(0.2, 1.0)),\n", "                transforms.RandomGrayscale(p=0.2),\n", "                transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n", "                transforms.RandomHorizontalFlip(),\n", "                transforms.ToTensor(),\n", "                transforms.Normalize(mean=mean, std=std),\n", "            ]\n", "        ),\n", "    }\n", "    return data_transforms[trans_type]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["datasets_path = {\n", "    \"office\": \"./data/office\",\n", "    \"office_home\": \"./data/officehome\",\n", "    \"visda17\": \"./data/visda17\",\n", "    \"domainnet\": \"./data/domainnet\",\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_dataset(\n", "    name,\n", "    domain,\n", "    txt=\"\",\n", "    suffix=\"\",\n", "    keep_in_mem=False,\n", "    ret_index=False,\n", "    image_transform=None,\n", "    use_mean_std=False,\n", "    image_size=224,\n", "):\n", "    if suffix != \"\":\n", "        suffix = \"_\" + suffix\n", "    if txt == \"\":\n", "        txt = f\"{domain}{suffix}\"\n", "    stat = f\"{name}_{domain}\" if use_mean_std else \"imagenet\"\n", "    if image_transform is not None and isinstance(image_transform, str):\n", "        transform = get_augmentation(image_transform, stat=stat, image_size=image_size)\n", "    return Imagelists(\n", "        f\"data/splits/{name}/{txt}.txt\",\n", "        datasets_path[name],\n", "        keep_in_mem=keep_in_mem,\n", "        ret_index=ret_index,\n", "        transform=transform,\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dataloader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pil_loader(path):\n", "    with open(path, \"rb\") as f:\n", "        img = Image.open(f)\n", "        return img.convert(\"RGB\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def worker_init_seed(worker_id):\n", "    np.random.seed(12 + worker_id)\n", "    random.seed(12 + worker_id)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_loader(dataset, batch_size=32, num_workers=4, is_train=True):\n", "    return torch.utils.data.DataLoader(\n", "        dataset,\n", "        batch_size=min(batch_size, len(dataset)),\n", "        num_workers=num_workers,\n", "        shuffle=is_train,\n", "        drop_last=is_train,\n", "        pin_memory=True,\n", "        worker_init_fn=worker_init_seed,\n", "    )"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}